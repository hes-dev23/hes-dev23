# Training Data

좋은 학습용 데이터를 만드는 방법에 대해 소개한다. 

## Sampling
학습용 데이터를 만들거나, train-validation-test를 위해 데이터를 나누거나 모니터링을 위해 샘플링하는 경우 등 ML 프로젝트에서 샘플릉은 자주 일어난다.
주로 많은 경우에, 샘플링은 필수적이다. 
프로세스에 맞게 데이터의 일부분을 추출해 가격적으로 저렴하고 더 빠르게 달성할 수 있다.
서로 다른 샘플링 방법과 워크플로우에 어떻게 적용되는지 이해한다면 샘플링 바이어스를 피할 수 있고, 효율성을 높힐 수 있다. 

### Nonprobability Sampling

- Convenience sampling: 가용성에 바탕하여 있는 데이터를 사용하는 샘플링
- Snowball sampling: 존재하는 샘플로 부터 작은 수의 샘플을 선택하고 점차적으로 늘려나가는 방식 
- Judgement sampling: 전문가를 활용하여 샘플링하는 기법
- Quota sampling: 일정한 방법으로 나누어진 그룹(슬라이스)에서 몇개씩 추출하는 방식

확률에 기반하지 않은 샘플링 기법은 빠르고 쉬운 방법이다. 
하지만 안정적인 모델 구성을 위해서는 확률 기반 샘플링을 활용하는 것이 좋다.

### Simple Random Sampling
모두에게 같은 확률을 적용하여 뽑아내는 방식을 의미한다. 
이 방법은 구현이 쉬우며, 많은 비중을 차지하지 않는 분류의 데이터들은 선택받지 못할 수 있는 단점이 존재한다.

### Stratified Sampling
심플 랜덤 샘플링의 단점을 해결하기 위해, 먼저 데이터를 그룹으로 나누고 각 그룹에 일정 비율을 뽑아내는 방식이다.
이 방법은 항상 가능하진 않고, multilabel task에서는 활용하기 어렵다.

### Weighted Sampling
각 샘플들이 확률에 기반한 weight를 받는 형태이다.
이 방법에서는 도메인 전문가의 도움을 받을 수 있다. 
또한 다른 분포의 데이터를 가지고 있을 때, true data와 비교하는 것에 도움이 된다. 

### Reservoir Sampling
Reservoir 샘플링은 스트리밍 데이터를 다룰 때 활용할 수 있는 기술이다. 
새롭게 들어오는 모든 항목들은 기존의 항목과 같은 확률로 선택되어 유지되고 또 버려진다. (n번째로 들어온 항목은 k/n의 확율로 살아남는다.)

### Importance Sampling
P 분포를 구성하기에 값이 비쌀 때, P와 유사한 Q를 적용하여 P(x)/Q(x)로 weight를 주어 샘플링하는 방식이다.
(이때, Q(x)가 proposal distribution 또는 importance distribution이다.)


## Labeling
대부분의 상용화된 ML 모델은 학습하기 위한 label이 필요한 supervised 모델이다.

### Hand Labels
사람이 직접 레이블링을 하는 방법이다. 
많은 전문가적 지식을 요구하는 작업으로 비싸고, 데이터 개인 정보에 대한 위협이 존재한다. 
또한 작업이 느리다는 단점이 존재한다.

#### Label multiplicity
다양한 소스로부터 들어오는 데이터의 경우 다양한 수준의 전문가적 지식을 동반한 사람에 의존하여 label이 생성된다. 
이들간 disagreement는 아주 흔하게 발생하며, 이를 해결하기 위해 문제를 명확하게 정의하는 것이 중요하다. 

#### Data lineage
다양한 소스로부터 들어오는 데이터가 융합된 경우, 문제가 발생했을 때, 새로운 데이터와 기존 데이터의 구분이 어려워지며 회복이 어렵다.
이러한 문제의 해결을 위해 데이터의 계보를 잘 관리하는 것을 Data lineage라고 한다.


### Natural Labels
로그와 같이 자연적으로 생기는 label을 natural label이라고한다.
추천시스템에서 추천은 클릭을 받아 좋은(positive) 것으로 추측하고 누르지 않는 경우(negative)로 판단할 수 있다.
모델에서 이러한 natural label을 생성하지 않는 경우에도 feedback을 모으기 위해 세팅할 수 있다.
산업에서는 이러한 자연 생성 label을 활용하는 task가 일반적이다.
클릭과 같이 유추할 수 있는 label을 implicit label, 명확한 피드백과 같이 명확한 의사가 포함되어있는 경우 explicit label이라고 한다.

#### Feedback loop length
모든 추천 시스템은 분단위 feedback 루프를 가지고 있지 않다, 몇 초 또는 몇 주나 월 단위의 길이가 될 수 있다.
적당한 길이의 feedback 윈도우를 설정하는 것은 중요하다.

### Handling the Lack of Labels

#### Weak supervision
휴리스틱에 기반하여 동작하도록 구성하는 방식이다, programatic labeling이라고도 한다. 
이론상으로 weak supervision을 위해서는 hand label이 필요없지만, 정확한 labeling function을 위해서는 몇몇 hand label이 필요하다. 
주로 강한 privacy를 가진 데이터를 위해 활용된다.
이 방법은 fully supervised labeling과 비슷할 정도로 간단하고 효과적이지만, 완벽하지 않다.

#### Semi-supervision
적은 수의 시작 label을 바탕으로 새로운 label을 생성해내는 방식이다. Weak supervision과 다르게 시작을 위해 label이 필요하다.
고전적인 semi-supervision의 방법으로는 self-training이 있다. 
clustering이나 k-nearest neighbors 알고리즘을 활용하여 같은 클러스터에 존재하는 지 확인할 수 있다. 
최근에는 perturbation(간섭을 집어넣는 방법)-based 방법들이 주를 이루고 있다.
몇몇 케이스에서는 semi-supervision방식이 supervised learning과 비슷한 성능을 보인다. 

#### Transfer learning
다른 task를 위해 학습된 모델을 현재 task에 맞춰서 재학습하는 방식이다.
zero-shot learning의 경우 재학습 없이 그대로 활용할 수 있다. 많은 경우에 주로 기본 모델을 fine-tune해야한다.
많은 label이 없을 때 활용될 수 있다.

#### Active learning
데이터 label의 효율성을 증가시키는 방법이다. query learning이라고 부르기도 한다.
random하게 label을 하는 것 대신에 평가지표나 휴리스틱을 활용해 모델에 도움이 되는 데이터 샘플을 label하는 방식이다.
(e.g. 경계선 근처에 있는 데이터를 잘 label하여 모델의 정확도를 올려주는 방식)


## Class Imbalance
클래스 불균형은 classification task에서 주로 발생하는 문제이다. 

### Challenges of Class Imbalance
클래스 불균형은 다음과 같은 영향을 미친다.
1. 비주류 클래스에 대한 학습의 실마리를 제공하지 못한다.
2. 모델이 optimal solution에 도달하지 못하도록 막는다.
3. error의 asymmetric cost(잘못된 예측에 대한 비용이 클 때)를 만들 수 있다. 

### Handling Class Imbalance
깊은 신경망 모델이 얕은 신경망 모델보다 불균형 데이터에 더욱 잘 작동한다는 연구가 있었다. 

#### Using the right evaluation metrics
모든 class를 동등하게 다루는 것은 불충분한 평가지표이다.
false positive 대비해서 true positive를 그려내면 ROC 커브를 그릴 수 있다.
그러나 F1과 recall과 마찬가지로 ROC 역시 postive class에 대해서 평가하므로, negative class를 어떻게 다루는지 알 수 없다.
따라서 상황에 맞는 적절한 평가지표를 선택하는 것이 중요하다.


#### Data-level methods: Resampling
모델이 학습을 더욱 쉽게 할 수 있도록 학습용 데이터의 분포를 변화 시키는 데이터 레벨의 방법도 존재한다.
가장 간단한 방법은 다수가 존재하는 class의 데이터를 임의로 지워서 소수의 class에 맞추는 방법이다.
이 방법은 decision boundary를 조금 더 명확하게 하고, 모델이 boundary 학습을 더욱 잘 할 수 있도록 만든다.

또한 소수의 class 데이터를 복제하여 SMOTE와 같은 방법을 사용할 수 있다.
이 방법은 low-dimensional 데이터에서 효율적인 방법임이 증명되었다. 

주의할 점은 sampling을 통해 모델을 학습시킬 때, 평가는 sampling된 데이터로 진행하면 안된다는 점이다.
under-sampling에서는 주요 데이터를 지우게 될 수도 있고, over-sampling을 통해 overfitting의 문제가 발생할 수 있다.

최근에는 2개의 phase로 나누어, 먼저 sampling된 데이터를 통해 학습 시킨 뒤, 학습된 모델을 전체 데이터에 대해 한 번 더 튜닝하는 방식을 활용하기도 한다.
또 다른 방법으로는 낮은 성능을 보이는 class를 더 많이 뽑고, 높은 성능을 보이는 class를 적게 뽑는 dynamic sampling을 활용하기도 한다.

#### Algorithm-level methods
알고리즘에서도 학습 데이터의 분포를 조절하여 class 불균형에 대응할 수 있도록 변경할 수 있다. 
loss function은 학습 과정을 만들어 내므로, 많은 알고리즘 레벨의 방법들이 loss function을 조정하는 방식을 이용한다.
잘못된 예측의 무게가 높은 경우에는 문제를 틀리는 것에 loss를 높게 잡는 등과 같은 방법을 활용한다.
##### Cost-sensitive learning
다른 class의 잘못된 분류는 각각 다른 cost를 발생시킨다. 
따라서 각각 다른 cost를 적용해서 학습할 수 있도록 한다.

##### Class-balanced loss
데이터의 각 class가 분포하는 비율에 따라 loss 값이 계산될 수 있도록 한다.

##### Focal loss
맞추기 어려운 경우에 대해 더 큰 loss를 부여하여 더 경계를 잘 찾을 수 있도록 한다. 

## Data Augmentation
학습데이터의 양을 늘리는 추세에 활용하기 좋은 방법이다. 
Data Augmenetation은 모델을 노이즈나 악의적인 공격들에 대해 조금 더 robust하도록 만들어준다. 
### Simple Label-Preserving Transformations
label을 유지한 채 조금의 변경을 주는 방법이다. 
예를 들어 그림의 경우, 자르거나 뒤집거나 돌리거나 역전시키거나 지우는 방법등을 활용할 수 있다. 
또는 문장에서 하나의 단어를 유사한 단어로 교체하는 방법을 활용할 수 있다. 

### Perturbation
perturbation도 label을 유지한 채 변경을 주는 방법 중 하나이다. 
그러나, perturbation의 경우는 모델이 틀린 결과를 도출하도록 속이는 기술로 사용되기도 한다.

주로 신경망 모델을 노이즈에 민감하다.
이러한 신경망 모델에 일부러 잘못된(deceptive) 데이터를 집어 넣어 잘못된 예측을 하도록하는 방법을 adversarial attack이라고 한다.
최근 자연어 처리에서 두각을 보이는 BERT에서도 이 방법을 활용해서 성능 증진을 가져오고 있다.

### Data Synthesis
데이터를 모으는 작업은 느리고 비용이 비싸기 때문에, 모델 성능 증진을 위해 일부 학습 데이터를 증폭시켜서 활용할 수 있다. 
자연어 처리에서는 탬플릿을 제공함으로써 모델이 저렴하게 학습을 시작할 수 있다. 
컴퓨터 비전 영역에서는 이산(discrete) label을 가진 기존의 학습 데이터들을 융합하여 연속되는 label 데이터로 증폭하는  mixup을 활용해볼 수 있다. 
mixup은 모델이 잘못된 label을 학습하는 것을 저하시켜주고, 잘못된 데이터를 집어넣은 것에 대해 강인한(robust) 결괄르 보일 수 있도록 한다.
 