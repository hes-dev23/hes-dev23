# Training Data

좋은 학습용 데이터를 만드는 방법에 대해 소개한다. 

## Sampling
학습용 데이터를 만들거나, train-validation-test를 위해 데이터를 나누거나 모니터링을 위해 샘플링하는 경우 등 ML 프로젝트에서 샘플릉은 자주 일어난다.
주로 많은 경우에, 샘플링은 필수적이다. 
프로세스에 맞게 데이터의 일부분을 추출해 가격적으로 저렴하고 더 빠르게 달성할 수 있다.
서로 다른 샘플링 방법과 워크플로우에 어떻게 적용되는지 이해한다면 샘플링 바이어스를 피할 수 있고, 효율성을 높힐 수 있다. 

### Nonprobability Sampling

- Convenience sampling: 가용성에 바탕하여 있는 데이터를 사용하는 샘플링
- Snowball sampling: 존재하는 샘플로 부터 작은 수의 샘플을 선택하고 점차적으로 늘려나가는 방식 
- Judgement sampling: 전문가를 활용하여 샘플링하는 기법
- Quota sampling: 일정한 방법으로 나누어진 그룹(슬라이스)에서 몇개씩 추출하는 방식

확률에 기반하지 않은 샘플링 기법은 빠르고 쉬운 방법이다. 
하지만 안정적인 모델 구성을 위해서는 확률 기반 샘플링을 활용하는 것이 좋다.

### Simple Random Sampling
모두에게 같은 확률을 적용하여 뽑아내는 방식을 의미한다. 
이 방법은 구현이 쉬우며, 많은 비중을 차지하지 않는 분류의 데이터들은 선택받지 못할 수 있는 단점이 존재한다.

### Stratified Sampling
심플 랜덤 샘플링의 단점을 해결하기 위해, 먼저 데이터를 그룹으로 나누고 각 그룹에 일정 비율을 뽑아내는 방식이다.
이 방법은 항상 가능하진 않고, multilabel task에서는 활용하기 어렵다.

### Weighted Sampling
각 샘플들이 확률에 기반한 weight를 받는 형태이다.
이 방법에서는 도메인 전문가의 도움을 받을 수 있다. 
또한 다른 분포의 데이터를 가지고 있을 때, true data와 비교하는 것에 도움이 된다. 

### Reservoir Sampling
Reservoir 샘플링은 스트리밍 데이터를 다룰 때 활용할 수 있는 기술이다. 
새롭게 들어오는 모든 항목들은 기존의 항목과 같은 확률로 선택되어 유지되고 또 버려진다. (n번째로 들어온 항목은 k/n의 확율로 살아남는다.)

### Importance Sampling
P 분포를 구성하기에 값이 비쌀 때, P와 유사한 Q를 적용하여 P(x)/Q(x)로 weight를 주어 샘플링하는 방식이다.
(이때, Q(x)가 proposal distribution 또는 importance distribution이다.)


## Labeling
대부분의 상용화된 ML 모델은 학습하기 위한 label이 필요한 supervised 모델이다.

### Hand Labels
사람이 직접 레이블링을 하는 방법이다. 
많은 전문가적 지식을 요구하는 작업으로 비싸고, 데이터 개인 정보에 대한 위협이 존재한다. 
또한 작업이 느리다는 단점이 존재한다.

#### Label multiplicity
다양한 소스로부터 들어오는 데이터의 경우 다양한 수준의 전문가적 지식을 동반한 사람에 의존하여 label이 생성된다. 
이들간 disagreement는 아주 흔하게 발생하며, 이를 해결하기 위해 문제를 명확하게 정의하는 것이 중요하다. 

#### Data lineage
다양한 소스로부터 들어오는 데이터가 융합된 경우, 문제가 발생했을 때, 새로운 데이터와 기존 데이터의 구분이 어려워지며 회복이 어렵다.
이러한 문제의 해결을 위해 데이터의 계보를 잘 관리하는 것을 Data lineage라고 한다.


### Natural Labels
로그와 같이 자연적으로 생기는 label을 natural label이라고한다.
추천시스템에서 추천은 클릭을 받아 좋은(positive) 것으로 추측하고 누르지 않는 경우(negative)로 판단할 수 있다.
모델에서 이러한 natural label을 생성하지 않는 경우에도 feedback을 모으기 위해 세팅할 수 있다.
산업에서는 이러한 자연 생성 label을 활용하는 task가 일반적이다.
클릭과 같이 유추할 수 있는 label을 implicit label, 명확한 피드백과 같이 명확한 의사가 포함되어있는 경우 explicit label이라고 한다.

#### Feedback loop length
모든 추천 시스템은 분단위 feedback 루프를 가지고 있지 않다, 몇 초 또는 몇 주나 월 단위의 길이가 될 수 있다.
적당한 길이의 feedback 윈도우를 설정하는 것은 중요하다.

### Handling the Lack of Labels

#### Weak supervision
휴리스틱에 기반하여 동작하도록 구성하는 방식이다, programatic labeling이라고도 한다. 
이론상으로 weak supervision을 위해서는 hand label이 필요없지만, 정확한 labeling function을 위해서는 몇몇 hand label이 필요하다. 
주로 강한 privacy를 가진 데이터를 위해 활용된다.
이 방법은 fully supervised labeling과 비슷할 정도로 간단하고 효과적이지만, 완벽하지 않다.

#### Semi-supervision
적은 수의 시작 label을 바탕으로 새로운 label을 생성해내는 방식이다. Weak supervision과 다르게 시작을 위해 label이 필요하다.
고전적인 semi-supervision의 방법으로는 self-training이 있다. 
clustering이나 k-nearest neighbors 알고리즘을 활용하여 같은 클러스터에 존재하는 지 확인할 수 있다. 
최근에는 perturbation(간섭을 집어넣는 방법)-based 방법들이 주를 이루고 있다.
몇몇 케이스에서는 semi-supervision방식이 supervised learning과 비슷한 성능을 보인다. 

#### Transfer learning
다른 task를 위해 학습된 모델을 현재 task에 맞춰서 재학습하는 방식이다.
zero-shot learning의 경우 재학습 없이 그대로 활용할 수 있다. 많은 경우에 주로 기본 모델을 fine-tune해야한다.
많은 label이 없을 때 활용될 수 있다.

#### Active learning
데이터 label의 효율성을 증가시키는 방법이다. query learning이라고 부르기도 한다.
random하게 label을 하는 것 대신에 평가지표나 휴리스틱을 활용해 모델에 도움이 되는 데이터 샘플을 label하는 방식이다.
(e.g. 경계선 근처에 있는 데이터를 잘 label하여 모델의 정확도를 올려주는 방식)


## Class Imbalance
클래스 불균형은 classification task에서 주로 발생하는 문제이다. 

### Challenges of Class Imbalance
클래스 불균형은 다음과 같은 영향을 미친다.
1. 비주류 클래스에 대한 학습의 실마리를 제공하지 못한다.
2. 모델이 optimal solution에 도달하지 못하도록 막는다.
3. error의 asymmetric cost(잘못된 예측에 대한 비용이 클 때)를 만들 수 있다. 

### Handling Class Imbalance

#### Using the right evaluation metrics

#### Data-level methods: Resampling

#### Algorithm-level methods

## Data Augmentation

### Simple Label-Preserving Transformations

### Perturbation

### Data Synthesis
