# chapter 3 Data Engineering Fundamentals

## Data Sources
ML 시스템은 다양한 소스로 부터오는 데이터를 활용한다. 
데이터는 각자 다른 성격을 띄고, 다른 목적과 다른 처리 방식을 가진다. 

사용자 입력 data - 다양한 형태를 가지며, 오염되어 있을 가능성이 크다. 주로 빠른 처리를 요구한다.
시스템 생성 data - 다양한 타입의 로그나 모델 예측 결과와 같은 시스템 출력을 포함한다. 주로 디버깅이나 어플리케이션의 개선을 위해 활용한다.
최대한 많은 내용을 보존하도록 하면 보기 어렵고 양이 빠르게 증가하는 문제가 있다. 유저의 행동과 같은 정보를 포함할 수 있다. 
내부 데이터베이스 - 다양한 서비스나 회사의 어플리케이션에 의해 생성된다. ML 시스템에 직접적으로 활용될 수도 있고, ML 시스템 구성요소에 의해 활용될 수도 있다. 
Third-party data - 데이터 회사에서 직접적인 고객이 아닌 퍼블릭 데이터를 모아 제공한다. 주로 제공 업체에 의해 정제된 후 판매된다. 

## Data Formats
다양한 소스로 부터 온 데이터는 다른 접근 패턴을 가진다. 
이러한 상황에서 아래에 대한 질문들이 떠오를 수 있다. 

1. multimodal 데이터를 어떻게 저장할 것인가?
2. 어디에 데이터를 저장할 것인가
3. 복잡한 모델을 어떻게 저장할 것인가?

데이터를 포멧에 맞게 변환하는 작업을 data serialization이라고 한다. 
이때, 사람이 읽을 수 있는지, 접근 패턴이 어떠한지, 텍스트로 저장할 것인지 바이너리로 저장할 것인지등에 따라 다양한 형태로 저장할 수 있다. 

### JSON
JSON - 언어에 종속적이지 않으며, 사람이 읽을 수 있는 key-value 패러다임이다. 많은 저장공간을 차지한다. 

### Row-Major Versus Column-Major Format
CSV - row-major, item에 대한 접근이 잦을 때 높은 활용도를 보인다. 데이터를 쓸 때 이점을 보인다. 
Parquet - column-major, 각 feature(column)에 대한 접근이 잦을 때 높은 활용도를 보인다.
*(pandas는 column-major Dataframe의 형태를 따르고, numpy는 row-major를 따른다.) 

### Text Versus Binary Format
CSV와 JSON은 텍스트 파일이며, Parquet은 바이너리 파일이다. 
텍스트 파일은 사람이 읽을 수 있다.
바이너리 파일은 저장소를 아낄 수 있다. 

## Data Model
Data Model은 어떻게 데이터를 표현할 것인가를 설명한다. 
데이터 모델에 따라 시스템이 설계되는 방식이 달라지고, 문제를 해결하는 방식도 달라진다.

### Relational Model
Relational Model은 관계(튜플의 집합)로 구성된 데이터들이고.
관계는 순서가 정의 되어 있지 않고, 주로 CSV나 Parquet 형태로 저장한다.
데이터 중복을 피하기 위해 정규화를 해서 저장하는데, 여러 관계에 데이터를 퍼지게 만들어 테이블이 커질 수록 조인 연산이 비싸지는 단점이 있다. 
SQL 등의 쿼리 언어로 데이터를 불러와서 활용한다. (declarative language - SQL은 데이터를 불러오는 방법보다, 어떤 데이터를 가지고 올 것인지 초점을 맞추고 있다.)

### NoSQL
제한된 스키마나, 스키마 관리는 고통스럽다. NoSQL 데이터 시스템에는 document model과 graph 모델이 있다. 
*(Not Only SQL로 많은 NoSQL 데이터 시스템은 관계형 모델도 지원한다.)

#### Document model
> data comes in self-contained documents 
모든 document는 같은 형태로 저장되어 있다고 가정된다.
각 document는 고유한 키를 가지고, 검색을 위해 활용할 수 있다.
document 모델은 강제하는 스키마가 존재하는 것은 아니지만, 읽혀야하는 데이터이므로, 저장되는 데이터들은 구조를 가지고 있다.
그렇지만 다른 테이블과의 조인 연산에는 비효율적이며 어려운 점들이 있다.
document model과 relational model의 서로 다른 장점때문에, 보통 같은 DB 시스템에서 다른 테스크에 두 모델 모두를 활용한다. 

#### Graph model
Graph DB에서는 모든 document가 우선순위를 가지고 관계를 유지한다.
이러한 이유 덕분에 관계를 바탕으로 검색이 더 빠르다. 

## Structured Versus Unstructured Data
미리 정의된 구조는 데이터가 더욱 분석하기 윕게 만들어준다. 
그러나 데이터를 집어 넣을 때마다 미리 정의된 구조에 맞춰 주어야하는 단점이 있다.

비지니스 요구사항은 시간이 지나면서 변하기 때문에, 미리 정의된 데이터 구조가 너무 엄격할 수 있다.
또한 통제가 불가능한 다양한 소스로 부터 데이터가 들어오기 때문에 이를 맞추는 것이 어려울 수 있다. 

이에 반해, 구조가 정해지지 않은 데이터는 지정된 데이터 구조가 있는 것은 아니지만, 구조를 뽑을 수 있는 암시적 패턴을 가지고 있다.
때문에 데이터가 조금 더 여유로운 저장소 옵션들을 허용한다.

> 정의된 구조의 데이터는 Data Warehouse에, 구조가 정해지지 않은 데이터는 Data Lake에 저장한다. 

## Data Storage Engines and Processing
Storage Engine은 데이터를 어떻게 저장하고 검색할지에 대한 구현이다. 따라서 팀의 상황에 맞게 필요한 데이터베이스의 타입을 이해하는 것이 좋다. 
일반적으로 데이터베이스는 transactional processing과 analytical processing의 두 가지 타입으로 최적화된다.

### Transactional and Analytical Processing

Transaction은 생성되면서 삽입되고, 경우에 따라 업데이트 되며, 필요하지 않을 때 삭제된다. 
이러한 과정을 OLTP(online transaction processing)이라고 한다. 
Transactional DB는 online transaction을 처리하기 위해 낮은 레이턴시와 높은 가용성을 요구한다. 
이에 따라 주로 ACID(atomicity, consistency, isolation, durability)를 생각하지만, 꼭 기준이 엄격한 ACID를 만족할 필요 없이 BASE(Basically Available, Soft state, and Eventual consistency)의 완화된 기준을 만족하면된다고도 한다.

transactional DB는 주로 row-major 이며, 분석형 질문에 효율적으로 어울리지 않는다.
이에 따라 Analytical DB로 OLAP(online analytical processing)의 관점에서 바라볼 수 있다. 

최근에는 transactional DB이지만 analytical록쿼리를 제공하거나 analytical DB이지만 transactional 쿼리를 제공하기도 한다.
또한 이전에는 processing과 storage가 연결되어 있었지만, 최근에는 분리되어 제공되는 서비스(같은 공간에 저장되어있지만 processing layer에 따라 다른 최적화)도 많다.
또한 이전에 online은 네트워크에 연결된 상태를 의미했으나, 지금은 production에 들어가 있는 상태를 의미한다.

### ETL: Extract, Transform, and Load

데이터가 소스로 부터 **추출**되고나면, 올바른 형태로 **변형**되어야 하며, 데이터베이스나 웨어하우스에 **로드**되어야 한다.
이과정을 ETL이라고 하며, 이는 ML이전에도 많이 활용되었다.
ETL이 지속적으로 활용됨에 따라, 데이터를 구조화된 형태로 관리하는 것에는 어려움이 있었다. 
이에 따라 몇몇 회사에서는 그냥 쌓아놓고 쓸 때 변형해서 사용하면 어떨까하는 ELT을 제안했다.
그러나 데이터의 양이 지속적으로 증가함에 따라 필요한 데이터를 raw 데이터에서 검색하는 것은 비효율적이었다.
추후 두 방법의 장점을 모두 활용할 수 있도록 data lake와 data warehouse를 활용하는 방법들로 발전해오고 있다.

## Modes of Dataflow

### Data Passing Through Databases
데이터 베이스를 통해서 데이터를 주고 받는 시스템에서는 두 프로세스 모두 하나의 같은 데이터베이스에 접근할 수 있어야한다. 
같은 데이터베이스를 활용하면서 read/write가 느려지고 latency 요구사항이 존재하는 경우는 활용하기 어렵다. 

### Data Passing Through Services
두 프로세스간 직접 데이터를 전달하고 받는 방법도 있다. 
request를 통해 프로세스간 소통이 이루어지므로 이러한 방법을 request-driven이라고 한다. 
두 프로세스는 같은 어플리케이션 내에서 이루어 질수도 있고, 다른 회사의 다른 어플리케이션이 될 수도 있다.
주로 REST나 RPC와 같은 형태로 request가 이루어지고, REST는 public API를 위해 주로 사용되고 RPC는 같은 조직에있는 서비스 사이의 요청을 다룰 때 사용된다.


### Data Passing Through Real-Time Transport
서비스가 많아질 수록 데이터의 전달 구조는 더욱 더 복잡해진다. 
Request-driven 구조는 동기의 방식으로 데이터를 전달한다. 
따라서 하나의 서비스가 다운되면 이로부터 데이터를 받는 모든 서비스가 동시에 다운된다. 
이러한 문제를 해결하기 위해서, 브로커를 두고 모든 서비스가 브로커와 연결된 형태를 가지도록 만들 수있다. 

기술적으로 데이터베이스는 브로커의 역할을 할 수 있다.
그렇지만 데이터베이스는 읽고 쓰는 시간이 너무 느려서 latency 요구사항을 맞추지 못하는 경우도 있다.
이에 따라 주로 in-memory 저장소를 브로커데이터로 활용한다. 
Real-time transport가 서비스간 데이터를 주고 받는 in-memory 저장소로 활용될 수 있다. 

Real-time transport에서 전달하는 데이터를 event라고 하고, 이러한 구조를 event-driven 또는 event bus라고 한다. 
request-driven 구조는 데이터보다 로직이 중요한 시스템에서 잘 동작하고, eventdirven은 데이터 위주의 시스템에서 더 잘 동작한다. 

real-time transport의 두 가지 주요한 종류는 pubsub와 message queue가 있다. 
**pubsub**에서는 아무 서비스가 real-time transport에 서로 다른 topic에 대해 publish할 수 있고, 이를 구독하는 모든 서비스는 해당 토픽을 읽을 수 있다. 
따라서 데이터를 생산하는 서비스는 데이터를 소비하는 서비스를 신경쓰지 않는다. 
데이터는 일정 주기가 지나면 삭제하거나 영구 저장소로 옮겨진다.
**message queue**에서는 의도한 소비자에게 메세지가 보내진다. 

## Batch Processing Versus Stream Processing
historical data는 종종 batch job을 통해 처리된다.
지난 기간 많은 연구들 덕분에 Map Reduce나 Spark와 같은 데이터 batch 처리를 효율적으로 할 수 있는 분산 시스템들이 많이 있다.
streaming 의 경우 batch job보다 짧은 주기로 실행이 되거나, 필요에 의해 언제든 실행될 수 있다. 
stream 처리의 경우 낮은 latency를 보여줄 수있으며, Apache Flink 등과 같이 효율적인 기술이 안정적으로 분산처리를 지원한다. 
또한 매번 새롭게 데이터를 집어 넣는게 아니라 한 번 계산된 정보를 유지할 수 있도록 하여 추가된 정보만 다루면 된다. 

주로 batch processing은 ML에서 상대적으로 자주 일어나지 않고, rating과 같이 변화가 적은 데이터(static feature)에 활용할 수 있다.
streaming processing은 자주 변화하는 feature(dynamic feature)를 계산할 때 사용할 수 있고, 택시 가격 예측 등에 활용할 수 있다.

많은 문제들은 batch와 streaming feature를 모두 요구한다. 
